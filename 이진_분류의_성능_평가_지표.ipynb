{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "이진 분류의 성능 평가 지표.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPcKK0D2Dqg2tghprPT+M2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/ML_DL/blob/main/%EC%9D%B4%EC%A7%84_%EB%B6%84%EB%A5%98%EC%9D%98_%EC%84%B1%EB%8A%A5_%ED%8F%89%EA%B0%80_%EC%A7%80%ED%91%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###이진 분류의 성능 평가 지표: \n",
        "1. Accuracy ( 정확도 ) : Accuracy는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 단순한 지표\n",
        "\t- 한계 :   \n",
        "        1. 이진 분류의 경우, 데이터의 구성에 따라 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지 않는다.\n",
        "\t\t2. 정확도는 불균형한 레이블 값 분포에서 분류 모델의 성능을 판단할 경우, 적합한 평가 지표가 아니다.\n",
        "\n",
        "2. Confusion Matrix ( 오차 행렬 ) : 이진 분류에서 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표\n",
        "\t- True/False: 실제와 예측이 일치하는가?\n",
        "\t- Positive/Negative: 뭘로 예측했는가?\n",
        "\t\t1. TN(True Negative, Negative Negative): 실제는 Negative인데, Negative로 예측함.\n",
        "\t\t2. FP(False Positive, Negative Positive): 실제는 Negative인데, Positive로 예측함.\n",
        "\t\t3. FN(False Negative, Positive Negative): 실제는 Positive인데, Negative로 예측함.\n",
        "\t\t4. TP(True Positive, Positive Positive): 실제는 Positive인데, Positive로 예측함.\n",
        "\n",
        "\t- 불균형한 레이블 클래스를 가지는 데이터에서는\n",
        "\t\t1. 많은 데이터 중 중점적으로 찾아야 하는 매우 적은 수의 레이블에 1, \n",
        "        2. 그렇지 않은 경우에 0을 부여하는 경우가 많다.\n",
        "\n",
        "3. Precision ( 정밀도 ) , Recall ( 재현율 ) \n",
        "\t- Precision : FP(실제는 0인데 예측은 1)을 낮추는 데에 초점\n",
        "\t- Recall : FN(실제는 1인데 예측 0)을 낮추는 데에 초점\n",
        "\n",
        "\t- Task에 따른 Precision, Recall의 상대적 중요도 : 보통은 Recall이 Positive보다 상대적으로 중요한 업무가 많지만, Precision이 더 중요한 지표인 경우도 있다.\n",
        "\t\t\n",
        "\t\t1. Recall이 중요한 케이스 : 암 검출, 금융사기 검출 같은 Task에서는 실제로 Positive인 얘들을 Negative로 예측하면 큰일난다.\n",
        "\t\t2. Precision이 중요한 케이스 : 스팸 검출 같은 Task에서는 실제로 Negative인 얘들을 Positive로 예측하면 큰일난다.\n",
        "\n",
        "\t- Precision/Recall Trade-off : recision과 Recall은 상호 보완적인 평가 지표이기 때문에 어느 한 쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉽다. 이를 Precision/Recall Trade-off라고 부른다.\n",
        "\n",
        "\n",
        "\n",
        "4. F1 score : F1 Score는 Precision과 Recall을 결합한 지표, Precision과 Recall이 어느 한 쪽으로 치우치지 않을 때 상대적으로 높은 값을 가진다.\n",
        "\t\n",
        "\n",
        "5. ROC Curve, AUC Score : ROC Curve와 이에 기반한 AUC Score는 이진 분류의 예측 성능 측정에서 중요하게 사용되는 지표\n",
        "\t\n",
        "\t- ROC Curve : ROC Curve가 가운데 직선에 가까울수록 성능이 떨어지는 것이며, 멀어질수록 성능이 뛰어난 것 \n",
        "\t\t1. FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지를 나타내는 곡선\n",
        "\t\t2. FPR을 X축으로, TPR을 Y축으로 잡은 그래프\n",
        "\t\t\t- TPR(민감도) : 실제 값 Positive가 정확히 예측되어야 하는 수준 , Recall과 정의가 같\n",
        "\t\t\t- FPR : 1-TNR (특이성) : 실제 값 Negative가 정확히 예측되어야 하는 수준\n",
        "\n",
        "\t- ROC-AUC Score : 결국 분류의 성능 지표로 사용되는 것은 ROC 곡선 면적에 기반한 AUC(Area Under Curve) 값\n",
        "\t\t1. AUC(Area Under Curve) 값은 ROC 곡선 밑의 면적을 구한 것으로, 1에 가까울수록 좋은 수치\n",
        "\t\t2. AUC 값이 커지려면, FPR이 작은 상태에서 알마나 큰 TPR을 얻을 수 있느냐가 관건\n",
        "\t\t\n",
        "\n",
        "\t\t\n",
        "\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ODfkkwdF4IzG"
      }
    }
  ]
}